# Machine-Learning-Training

This repository showcases a wide range of machine learning techniques and methodologies implemented during my internship. It includes comprehensive examples of regression, classification, data preprocessing, feature engineering, and optimization techniques using Python. The projects are structured to highlight real-world data processing workflows and model training.

Highlights:

Regression Techniques: Implementation of linear regression, polynomial regression, ridge regression, and lasso regression for predicting weights based on fish length and other features.

Classification Models: Binary and multi-class classification using logistic regression, k-nearest neighbors (KNN), decision trees, random forest, and gradient boosting.

Feature Engineering: Creation of polynomial features and standardization for improved model performance.
Optimization: Use of cross-validation, grid search, and random search for hyperparameter tuning.

Visualization: Scatter plots, decision boundaries, feature importance graphs, and learning curves to interpret model performance.

Data Preprocessing: Techniques such as standard scaling, data splitting, and stratified sampling to ensure robust model training.

**Special Implementations**: Applications of logistic regression (sigmoid and softmax functions) and analysis of image data using pixel-based mean values.

Technologies Used:
Python libraries: NumPy, pandas, scikit-learn, Matplotlib, SciPy, and more.
